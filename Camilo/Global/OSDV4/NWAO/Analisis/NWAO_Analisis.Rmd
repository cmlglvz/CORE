---
title: "OSD_V4_NWAO_Analisis"
author: "Camilo Gálvez A."
output: html_document
---

#Libraries
```{r libraries, echo=TRUE, message=TRUE, warning=TRUE, include=FALSE}
library(tidyverse)
library(leaflet)
library(data.table)
library(vegan)
library(treemap)
library(UpSetR)
library(RColorBrewer)
library(plotly)
library(Biostrings)
library(DECIPHER)
library(dendextend)
library(heatmaply)
library(htmlwidgets)
library(hrbrthemes)
```


```{r dataframes, echo=TRUE, message=TRUE, warning=TRUE}
NWAO <- read.csv("/Users/Artemis/Documents/GitHub/CORE/Camilo/Global/OSDV4/NWAO/DADA2/seqtab_nonchim_nwao.csv", 
                 header = TRUE, 
                 sep = ";", 
                 skip = 0, 
                 fill = TRUE, 
                 row.names = 1)
NWAO <- apply(NWAO, 2, function(x) as.numeric(as.integer(x))) %>% as.data.frame()
samples <- c("C1A17", "C1F18", "C1A18", "C2A17", "C2F18", "C2A18", "C3A17", "C3F18", "C3A18", "C4A17", "C4F18", "C4A18", 
             "F1A17", "F1F18", "F1A18", "F2A17", "F2F18", "F2A18", "F3A17", "F3F18", "F3A18", "F4A17", "F4F18", "F4A18", 
             "H1A17", "H1F18", "H1A18", "H2A17", "H2F18", "H2A18", "H3A17", "H3F18", "H3A18", "H4A17", "H4F18", "H4A18", 
             "P1F18", "P1A18", "P2F18", "P3F18", "P4F18", 
             "Q1A17", "Q1F18", "Q2A17", "Q2F18", "Q3A17", "Q3F18", "Q3A18", "Q4A17", "Q4F18", "Q4A18", 
             "L1A17", "L1F18", "L1A18", "L2A17", "L2F18", "L2A18", "L3A17", "L3F18", "L3A18", "L4A17", "L4F18", "L4A18")
rownames(CORE) <- samples
write.csv2(CORE, "CORE_ASV_Abundance.csv")

TAXA <- read.csv("/Users/Artemis/Documents/GitHub/CORE/Camilo/DADA2/taxa.csv", 
                 header = TRUE, 
                 sep = ";", 
                 skip = 0) %>% 
  dplyr::rename(Seq = X) %>%
  add_column(ASV = c(str_glue("ASV000{1:9}"), 
                     str_glue("ASV00{10:99}"), 
                     str_glue("ASV0{100:999}"), 
                     str_glue("ASV{1000:6192}")), 
             .after = "Seq")
rownames(TAXA) <- TAXA[,1]
write.csv2(TAXA, "CORE_TAXA.csv")

print(all(colnames(CORE)%in%rownames(TAXA))) #If TRUE you can continue
```


#Filtro de ASV según asignación taxonómica
```{r ASV filter, echo=TRUE, message=TRUE, warning=TRUE}
#Me deshago de las secuencias de ASV que no fueron asignadas a nivel de Reino y Supergrupo
unassigned <- TAXA[rowSums(is.na(TAXA[, c(3,4)])) > 0, ]
nada <- TAXA[rowSums(is.na(TAXA[3])) > 0, ]
na.seq <- unassigned[,1]
mTAXA <- TAXA[!(row.names(TAXA) %in% all_of(na.seq)),]
write.csv2(mTAXA, "Filtered_CORE_TAXA.csv")
mCORE <- dplyr::select(CORE, -all_of(na.seq))
write.csv2(mCORE, "Filtered_CORE_ASV_Abundance.csv")

print(all(colnames(mCORE)%in%rownames(mTAXA))) #If TRUE you can continue
```


#Rarefacción
```{r Rarefaction, echo=TRUE, message=TRUE, warning=TRUE}
rare.all <- sort(rowSums(mCORE)) #To identify the sample with the smallest number of observations, which will be used as the number of observations to rarefy samples

rrfy <- rarefy(mCORE, rare.all[1]) #rarefaction use the smallest number of observations per sample to extrapolate the expected number if all other samples only had that number of observations
rrfy #Gives an "expected" rarefied number of species (not observations) if only "rare.all[1]" individuals were present per sample

png("/Users/Artemis/Documents/GitHub/CORE/Camilo/Imagenes/Rarecurve_mCORE.png", width = 12, height = 6, units = "in", res = 300)
par(mar = c(5.1, 4.1, 4.1, 2.1), oma = c(0, 0, 0, 0))
rarecurve(x = mCORE, col = "blue", lwd = 2, las = 1, label = TRUE, step = 10, cex = 0.5)
dev.off()

rareCORE <- as.data.frame(rrarefy(mCORE, rrfy[1]))
write.csv2(rareCORE, file = "Rarefacted_filt_CORE_ASV_Abundance.csv")
```


#Unify abundance and taxonomic dataframes
```{r}
Union <- as.data.frame(t(mCORE))
Union <- mutate(Union, Seq = all_of(rownames(Union)), .before = "C1A17")
Union <- mutate(Union, 
                Cha = rowSums(Union[2:13]), 
                Fla = rowSums(Union[14:25]), 
                Hu = rowSums(Union[26:37]), 
                Pc = rowSums(Union[38:42]), 
                Qin = rowSums(Union[43:52]), 
                LC = rowSums(Union[53:64]), 
                Total = rowSums(Union[2:64])
                )
ATs <- inner_join(Union, mTAXA, by = "Seq") %>% relocate(ASV, .after = Seq)
rownames(ATs) <- all_of(ATs[,1])
write.csv2(ATs, "Taxonomic_and_Abundance_CORE.csv")
```


#UpSet preparation
```{r preparation, echo=TRUE, message=TRUE, warning=TRUE}
asv <- ATs[,2]
edited <- ATs[, -c(2,72:80)]
rownames(edited) <- asv
write.csv2(edited, "edited_Taxonomic_and_Abundance_CORE.csv")
APATs <- edited[, -1]
APATs <- vegan::decostand(APATs, method = "pa")
APATs <- add_column(APATs, Seq = all_of(edited$Seq), .before = "C1A17")
write.csv2(APATs, "Absence_Presence_CORE.csv")
```


#Complete UpSet
```{r Complete, echo=TRUE, message=TRUE, warning=TRUE}
aus.pres <- read.csv("Absence_Presence_CORE.csv", 
                     header = TRUE, 
                     sep = ";", 
                     dec = ".", 
                     skip = 0)

png("/Users/Artemis/Documents/GitHub/CORE/Camilo/Imagenes/Complete_UpSet.png", width = 50, height = 23, units = "in", res = 300)
upset(aus.pres, 
      nsets = 6, 
      nintersects = NA, 
      sets = c("Qin", "LC", "Pc", "Hu", "Fla", "Cha"), 
      empty.intersections = "on", 
      keep.order = TRUE, 
      point.size = 3.5, 
      line.size = 1.5, 
      text.scale = 2, 
      mainbar.y.label = "Sites Intersections", 
      sets.x.label = "ASV per sampling site"
      )
dev.off()
```


#Shorter UpSet
```{r Shorter, echo=TRUE,message=TRUE,warning=TRUE}
png("/Users/Artemis/Documents/GitHub/CORE/Camilo/Imagenes/Shorter_UpSet.png", width = 40, height = 21, units = "in", res = 600)
upset(aus.pres, 
      nsets = 6,
      nintersects = NA, 
      sets = c("Qin", "LC", "Pc", "Hu", "Fla", "Cha"), 
      intersections = list("Qin", "LC", "Pc", "Hu", "Fla", "Cha", 
                           list("Cha", "Fla"), 
                           list("Fla", "Hu"), 
                           list("LC", "Qin"), 
                           list("Hu", "LC"), 
                           list("Cha", "Hu"), 
                           list("Cha", "Qin"), 
                           list("Pc", "LC"), 
                           list("Hu", "Pc"), 
                           list("Fla", "Qin"), 
                           list("Hu", "Qin"), 
                           list("Fla", "LC"), 
                           list("Cha", "LC"), 
                           list("Pc", "Qin"), 
                           list("Fla", "Pc"), 
                           list("Cha", "Pc"), 
                           list("Cha", "Fla", "Hu"), 
                           list("Hu", "Pc", "LC"), 
                           list("Fla", "Hu", "Qin"), 
                           list("Cha", "Fla", "Qin"), 
                           list("Fla", "Hu", "Pc"), 
                           list("Hu", "LC", "Qin"), 
                           list("Cha", "Fla", "Pc"), 
                           list("Cha", "Fla", "Hu", "Qin"), 
                           list("Cha", "Fla", "Hu", "Pc"), 
                           list("Cha", "Fla", "Hu", "LC"), 
                           list("Fla", "Hu", "LC", "Qin"), 
                           list("Cha", "Fla", "Qin", "LC"), 
                           list("Cha", "Fla", "Hu", "Qin", "LC"), 
                           list("Cha", "Fla", "Hu", "Pc", "Qin"), 
                           list("Cha", "Fla", "Hu", "Pc", "LC")
                           ),
      empty.intersections = "on", 
      keep.order = TRUE, 
      query.legend = "top", 
      point.size = 3.5, 
      line.size = 1.5, 
      text.scale = 2, 
      mainbar.y.label = "Sites Intersections", 
      sets.x.label = "ASV per sampling site")
dev.off()
```


#Selected UpSet
```{r Selected, echo=TRUE, message=TRUE, warning=TRUE}
#Modify this according to selected intersections from previous UpSet
png("/Users/Artemis/Documents/GitHub/CORE/Camilo/Imagenes/Selected_UpSet.png", width = 30, height = 15, units = "in", res = 300)
upset(aus.pres, 
      nsets = 6,
      nintersects = NA, 
      sets = c("Cha", "Fla", "Hu", "Pc", "LC", "Qin"), 
      intersections = list("Qin", "LC", "Pc", "Hu", "Fla", "Cha", 
                           list("Cha", "Fla"), 
                           list("Hu", "Pc"), 
                           list("Qin", "LC"), 
                           list("Fla", "Pc"), 
                           list("Cha", "Hu", "Qin"), 
                           list("Fla", "Pc", "LC"), 
                           list("Cha", "Fla", "Qin", "LC"), 
                           list("Hu", "Pc", "Qin", "LC"), 
                           list("Cha", "Fla", "Hu", "Pc"), 
                           list("Cha", "Fla", "Hu", "Pc", "LC"), 
                           list("Cha", "Fla", "Hu", "Pc", "Qin"), 
                           list("Cha", "Fla", "Hu", "Pc", "LC", "Qin")
                           ),
      empty.intersections = "on", 
      keep.order = TRUE, 
      query.legend = "top", 
      queries = list(list(query = intersects, params = "Cha", color = "#E94144", active = TRUE, query.name = "Unique Chañaral ASV"), 
                     list(query = intersects, params = "Fla", color = "#F3722C", active = TRUE, query.name = "Unique Flamenco ASV"), 
                     list(query = intersects, params = "Hu", color = "#F8961E", active = TRUE, query.name = "Unique Huasco ASV"), 
                     list(query = intersects, params = "Pc", color = "#F9C74F", active = TRUE, query.name = "Unique Punta Choros ASV"), 
                     list(query = intersects, params = "LC", color = "#43AA8B", active = TRUE, query.name = "Unique Las Cruces ASV"), 
                     list(query = intersects, params = "Qin", color = "#577590", active = TRUE, query.name = "Unique Quintero ASV"), 
                     list(query = intersects, params = list("Cha", "Fla", "Hu", "Pc"), color = "#16DB93", active = TRUE, query.name = "Metal axis shared ASV"), 
                     list(query = intersects, params = list("Cha", "Fla", "Hu", "Pc", "LC", "Qin"), color = "#FF0000", active = TRUE, query.name = "Total shared ASV")
                     ), 
      point.size = 3.5, 
      line.size = 1.5, 
      text.scale = 2, 
      mainbar.y.label = "Sites Intersections", 
      sets.x.label = "ASV per sampling site")
dev.off()
```


```{r Tax.sum, echo=TRUE,message=TRUE,warning=TRUE}
Tax.sum <- function(OTU.Table, Tax.Table, Tax.lvl ){
  z <- NULL
  y <- NULL
  for (i in 1:length(unique(Tax.Table[colnames(OTU.Table),Tax.lvl]))) {
    if (length(OTU.Table[,which(Tax.Table[colnames(OTU.Table),Tax.lvl]==unique(Tax.Table[colnames(OTU.Table),Tax.lvl])[i])])!=length(rownames(OTU.Table))) {
      z <- which(Tax.Table[colnames(OTU.Table),Tax.lvl]==unique(Tax.Table[colnames(OTU.Table),Tax.lvl])[i])
      y <- cbind(y, apply(OTU.Table[,which(Tax.Table[colnames(OTU.Table),Tax.lvl]==unique(Tax.Table[colnames(OTU.Table),Tax.lvl])[i])], 1, function(x) sum(x)))
    } else {
      y <- cbind(y, OTU.Table[,which(Tax.Table[colnames(OTU.Table),Tax.lvl]==unique(Tax.Table[colnames(OTU.Table),Tax.lvl])[i])])
    }
  }
  colnames(y) <- unique(Tax.Table[colnames(OTU.Table),Tax.lvl])
  invisible((y))
}
```


```{r Phylum clustering, echo=TRUE,message=TRUE,warning=TRUE}
Phylum <- Tax.sum(mCORE, mTAXA, 5) %>% 
  t() %>% 
  as.data.frame() %>% 
  dplyr::mutate(Color = c("#24F205", "#FDFBE3", "#FDFBE3", "#FDFBE3", "#60F649", "#88F877", "#FDFBE3", "#AFFAA4", "#FDFBE3", "#FDFBE3", 
                   "#FDFBE3", "#FDFBE3", "#88F877", "#C8FBC1", "#FDFBE3", "#E0FDDC", "#FDFBE3", "#FDFBE3", "#FDFBE3", "#FDFBE3", 
                   "#FBFDE3", "#000000", "#FDFBE3", "#FDFBE3", "#FDFBE3", "#FDFBE3", "#FDFBE3", "#FDFBE3", "#FDFBE3", "#FDFBE3", 
                   "#FDFBE3", "#FDFBE3", "#FDFBE3", "#FDFBE3", "#FDFBE3", "#FDFBE3")
         )
Phylum <- dplyr::mutate(Phylum, 
                        Chanaral = rowSums(Phylum[1:12]), 
                        Flamenco = rowSums(Phylum[13:24]), 
                        Huasco = rowSums(Phylum[25:36]), 
                        Pta.Choros = rowSums(Phylum[37:41]), 
                        Quintero = rowSums(Phylum[42:51]), 
                        LasCruces = rowSums(Phylum[52:63]), 
                        Total = rowSums(Phylum[1:63]), 
                        .after = "L4A18")
Phylum <- Phylum[order(Phylum$Total, decreasing = TRUE),]
write.csv2(Phylum, "Phylum_CORE_Abundance_and_color.csv")
```


```{r phylum visualization, echo=TRUE,message=TRUE,warning=TRUE}
png("/Users/Artemis/Documents/GitHub/CORE/Camilo/Imagenes/Fig_4_Contribution_Distribution_Phylum.png", width = 17, height = 15, units = "in", res = 600)
treemap::treemap(read.csv("Phylum_CORE_Abundance_and_color.csv", 
                          header = TRUE, 
                          sep = ";", 
                          dec = ".", 
                          skip = 0), 
                 index = "X", 
                 vSize = "Total", 
                 type = "color", 
                 vColor = "Color", 
                 position.legend = "none", 
                 fontsize.labels = 20, 
                 fontsize.title = 30, 
                 title = "Sequence/ASV distribution and contribution", 
                 title.legend = NA, 
                 border.col = NA
                 )
dev.off()

png("/Users/Artemis/Documents/GitHub/CORE/Camilo/Imagenes/Fig_4_Legend.png", width = 10, height = 7, units = "in", res = 600)
plot.new()
par(mar = c(0,0,0,0), oma = c(0,0,0,0))
legend("center", 
       legend = read.csv("Phylum_CORE_Abundance_and_color.csv", 
                         header = TRUE, 
                         sep = ";", 
                         dec = ".", 
                         skip = 0)[,1], 
       cex = 1.2, 
       ncol = 1, 
       fill = Phylum$Color, 
       x.intersp = 0.3, 
       xjust = 0.3, 
       yjust = 0.5, 
       y.intersp = 1, 
       bty = "n", 
       adj = 0, 
       text.width = 0.3, 
       pt.cex = 0.3)
dev.off()
```


```{r relative function, echo=TRUE,message=TRUE,warning=TRUE}
rltv.Otu.Table <- function(x) {
  x.Data.rltv <- NULL
  for (i in 1:dim(x)[1]) {
    x.Data.rltv <- rbind(x.Data.rltv, x[i,]/apply(x, 1, function(x) sum(x))[i])
  }
  rownames(x.Data.rltv) <- rownames(x)
  invisible(x.Data.rltv)
}
```


```{r}
rltv.abun <- rltv.Otu.Table(Tax.sum(mCORE, mTAXA, 5)) %>% as.data.frame()
write.csv2(rltv.abun, "CORE_Relative_Abundance_dataframe.csv")
```


```{r}
png("/Users/Artemis/Documents/GitHub/CORE/Camilo/Imagenes/Fig_5_CORE_Relative_Abundance.png", width = 30, height = 11, units = "in", res = 600)
par(mar = c(5.1,4.1,4.1,2.1), oma = c(0,0,0,0))
barplot(t(rltv.abun), 
        border = NA, 
        ylab = "Relative Abundance", 
        ylim = c(0,1), 
        axes = TRUE, 
        col = c("#24F205", "#FDFBE3", "#FDFBE3", "#FDFBE3", "#60F649", "#88F877", "#FDFBE3", "#AFFAA4", "#FDFBE3", "#FDFBE3", 
                "#FDFBE3", "#FDFBE3", "#88F877", "#C8FBC1", "#FDFBE3", "#E0FDDC", "#FDFBE3", "#FDFBE3", "#FDFBE3", "#FDFBE3", 
                "#FBFDE3", "#000000", "#FDFBE3", "#FDFBE3", "#FDFBE3", "#FDFBE3", "#FDFBE3", "#FDFBE3", "#FDFBE3", "#FDFBE3", 
                "#FDFBE3", "#FDFBE3", "#FDFBE3", "#FDFBE3", "#FDFBE3", "#FDFBE3"), 
        las = 2, 
        cex.names = 0.8, 
        cex.axis = 0.9)
dev.off()

png("/Users/Artemis/Documents/GitHub/CORE/Camilo/Imagenes/Fig_5_Legend.png", width = 3, height = 5, units = "in", res = 600)
plot.new()
par(mar = c(0,0,0,0), oma = c(0,0,0,0))
legend("center", 
       legend = colnames(rltv.abun), 
       cex = 1, 
       ncol = 1, 
       fill = c("#24F205", "#FDFBE3", "#FDFBE3", "#FDFBE3", "#60F649", "#88F877", "#FDFBE3", "#AFFAA4", "#FDFBE3", "#FDFBE3", 
                "#FDFBE3", "#FDFBE3", "#88F877", "#C8FBC1", "#FDFBE3", "#E0FDDC", "#FDFBE3", "#FDFBE3", "#FDFBE3", "#FDFBE3", 
                "#FBFDE3", "#000000", "#FDFBE3", "#FDFBE3", "#FDFBE3", "#FDFBE3", "#FDFBE3", "#FDFBE3", "#FDFBE3", "#FDFBE3", 
                "#FDFBE3", "#FDFBE3", "#FDFBE3", "#FDFBE3", "#FDFBE3", "#FDFBE3"), 
       x.intersp = 0.1, 
       xjust = 0.1, 
       yjust = 0.3, 
       y.intersp = 1.2, 
       bty = "n", 
       adj = 0, 
       text.width = 0.1, 
       pt.cex = 0.1)
dev.off()
```


```{r}
ppe.taxa <- dplyr::filter(mTAXA,
                          Division == "Chlorophyta" | Division == "Ochrophyta" | Division == "Cryptophyta" | Division == "Cryptophyta:nucl" | Division == "Haptophyta" | Division == "Katablepharidophyta" | Division == "Rhodophyta")
write.csv2(ppe.taxa, "/Users/Artemis/Documents/GitHub/CORE/Camilo/Analisis/PPE/CORE_PPE_TAXA.csv")
ppe.asv <- select(mCORE, all_of(ppe.taxa$Seq))
write.csv2(ppe.asv, "/Users/Artemis/Documents/GitHub/CORE/Camilo/Analisis/PPE/CORE_PPE_ASV_Abundance.csv")
ppe.un <- as.data.frame(t(ppe.asv)) %>% dplyr::mutate(Seq = all_of(ppe.taxa$Seq), .before = "C1A17")
ppe.un <- mutate(ppe.un, 
                 Chanaral = rowSums(ppe.un[2:13]), 
                 Flamenco = rowSums(ppe.un[14:25]), 
                 Huasco = rowSums(ppe.un[26:37]), 
                 Pta.Choros = rowSums(ppe.un[38:42]), 
                 Quintero = rowSums(ppe.un[43:52]), 
                 LasCruces = rowSums(ppe.un[53:64]), 
                 Total = rowSums(ppe.un[2:64])
                 )
ppe.at <- inner_join(ppe.un, ppe.taxa, by = "Seq") %>% relocate(ASV, .after = Seq)
rownames(ppe.at) <- all_of(ppe.at[,1])
write.csv2(ppe.at, "/Users/Artemis/Documents/GitHub/CORE/Camilo/Analisis/PPE/Taxonomic_and_Abundance_PPE.csv")
```


```{r}
verdes <- ppe.at[,2]
vedited <- ppe.at[, -c(2,72:80)]
rownames(vedited) <- verdes
write.csv2(vedited, "/Users/Artemis/Documents/GitHub/CORE/Camilo/Analisis/PPE/edited_taxonomic_and_abundance_PPE.csv")
ppe.apats <- vedited[,-1]
ppe.apats <- vegan::decostand(ppe.apats, method = "pa") %>% add_column(Seq = all_of(vedited$Seq), .before = "C1A17")
write.csv2(ppe.apats, "/Users/Artemis/Documents/GitHub/CORE/Camilo/Analisis/PPE/Absence_Presence_PPE.csv")
```


#PPE UpSet
```{r}
aps.ppe <- read.csv2("/Users/Artemis/Documents/GitHub/CORE/Camilo/Analisis/PPE/Absence_Presence_PPE.csv", 
                     header = TRUE, 
                     sep = ";", 
                     dec = ".", 
                     skip = 0)

png("/Users/Artemis/Documents/GitHub/CORE/Camilo/Imagenes/PPE/Fig_6_Complete_PPE_UpSet.png", width = 50, height = 23, units = "in", res = 600)
upset(aps.ppe, 
      nsets = 6, 
      nintersects = NA, 
      sets = c("LasCruces", "Quintero", "Pta.Choros", "Huasco", "Flamenco", "Chanaral"), 
      empty.intersections = "on", 
      point.size = 3.5, 
      line.size = 1.5, 
      text.scale = 2, 
      mainbar.y.label = "Sites intersections", 
      sets.x.label = "ASV per sampling site"
      )
dev.off()
```


```{r shared PPE,echo=TRUE,message=TRUE,warning=TRUE}
shared <- aps.ppe %>% 
  dplyr::filter(Chanaral == 1 & Flamenco == 1 & Huasco == 1 & Pta.Choros == 1 & Quintero == 1 & LasCruces == 1)
#we can use de corresponding sequences to extract abundance and taxonomic assignation for theses ASV
sha.abun <- dplyr::select(ppe.asv, all_of(shared$Seq))
write.csv2(sha.abun, "/Users/Artemis/Documents/GitHub/CORE/Camilo/Analisis/PPE/Shared/Shared_PPE_CORE_ASV_Abundance.csv")
sha.taxa <- dplyr::filter(ppe.taxa, ppe.taxa$Seq %in% all_of(shared$Seq))
write.csv2(sha.taxa, "/Users/Artemis/Documents/GitHub/CORE/Camilo/Analisis/PPE/Shared/Shared_PPE_CORE_TAXA.csv")
```


```{r}
nms <- paste(sha.taxa$ASV, sha.taxa$Species, sep = "_")
fasta <- data.frame(names = nms, sequences = all_of(sha.taxa$Seq))
seqRFLP::dataframe2fas(fasta, "/Users/Artemis/Documents/GitHub/CORE/Camilo/Analisis/PPE/Shared/Shared_PPE_ASV_CORE.fasta")
#Align sequences with MUSCLE5
```


```{r}
alignment <- "/Users/Artemis/Documents/GitHub/CORE/Camilo/Analisis/PPE/Shared/Alignment/shared_alignment.fasta"
dbConn <- dbConnect(SQLite(), ":memory:")
Seqs2DB(alignment, type = "FASTA", dbFile = dbConn, "")
x <- dbGetQuery(dbConn, "select description from Seqs")$description
Add2DB(myData = data.frame(identifier = x, stringsAsFactors = FALSE), dbConn)
consensus <- IdConsensus(dbConn, threshold = 0.3, minInformation = 0.1)
distance.matrix <- DistanceMatrix(consensus, correction = "Jukes-Cantor", processors = NULL, verbose = TRUE)
dendrogram <- IdClusters(distance.matrix, 
                         method = "ML", 
                         showPlot = TRUE, 
                         type = "dendrogram", 
                         myXStringSet = consensus, 
                         processors = NULL, 
                         verbose = TRUE)
dbDisconnect(dbConn)
#Selected model was TN93+G4
```


```{r}
clust <- as.dendrogram(as.hclust(dendrogram)) %>% 
  set("branches_lwd", 0.3) %>% 
  ladderize(right = TRUE)
plot(clust)
```


```{r}
shasv <- sha.abun
colnames(shasv) <- nms
multi.align <- readDNAMultipleAlignment("/Users/Artemis/Documents/GitHub/CORE/Camilo/Analisis/PPE/Shared/Alignment/shared_alignment.fasta", format = "fasta")
multi.string <- as(multi.align, "DNAStringSet")
BrowseSeqs(multi.string, htmlFile = "/Users/Artemis/Documents/GitHub/CORE/Camilo/Imagenes/PPE/Shared/shared_PPE_multiple_alignment.html")
smatrix <- as.matrix(multi.align) %>% rownames() %>% as.vector()
print(all(colnames(shasv)%in%gtools::mixedsort(smatrix, decreasing = FALSE)))
sort.abun <- shasv[, rownames(as.matrix(multi.align))]
norm.hel <- heatmaply(normalize(decostand(sort.abun, method = "hellinger")), 
                      Colv = clust, 
                      Rowv = NA, 
                      main = "Shared PPE ASVs across all sites clustered by maximum likelihood", 
                      margins = c(50,50,70,0), 
                      grid_gap = 1, 
                      width = 1920, 
                      height = 1080, 
                      subplot_heights = c(0.35, 0.65), 
                      color = viridis(n = 256, 
                                      alpha = 1, 
                                      begin = 0, 
                                      end = 1, 
                                      option = "viridis")
                      )
saveWidget(norm.hel, file = "/Users/Artemis/Documents/GitHub/CORE/Camilo/Imagenes/PPE/Shared/hellinger_normalized_heatmap.html")
```


```{r}
rcc.shared <- readDNAMultipleAlignment("/Users/Artemis/Documents/GitHub/CORE/Camilo/Analisis/PPE/Shared/Alignment/rcc_sha_align.fasta", format = "fasta")
rcc.mstring <- as(rcc.shared, "DNAStringSet")
BrowseSeqs(rcc.mstring, htmlFile = "/Users/Artemis/Documents/GitHub/CORE/Camilo/Imagenes/PPE/Shared/Tree/RCC_Shared_PPE_ASV_multiple_alignment.html")
masked <- maskGaps(x = rcc.shared, min.fraction = 0.3, min.block.width = 4)
mskd <- as(masked, "DNAStringSet")
BrowseSeqs(myXStringSet = mskd, htmlFile = "/Users/Artemis/Documents/GitHub/CORE/Camilo/Imagenes/PPE/Shared/Tree/Masked_RCC_Shared_PPE_ASV_multiple_alignment.html")
consensusViews(masked)
writeXStringSet(mskd, filepath = "/Users/Artemis/Documents/GitHub/CORE/Camilo/Analisis/PPE/Shared/Alignment/masked_rcc_shared_align.fasta", format = "fasta")
#Externally perform the phylogenetic analysis (MEGA or whatever tool you like)
```

#Get shared sequences and start tree, it's going to take a while. Also read about network analysis THEN keep with heatmap!
#Keep up with the good work


#Nueva inspiracion
#Nuevos heatmaps pero solo con dos intersecciones, para ver si es que existe info que no estemos viendo.
#Las intersecciones serán Cha-Fla, Hu-Pc, Cha-Hu.
```{r}
chafla <- aps.ppe %>% dplyr::filter(Chanaral == 1 & Flamenco == 1 & Huasco == 0 & Pta.Choros == 0 & Quintero == 0 & LasCruces == 0)
chfl.abun <- dplyr::select(ppe.asv, all_of(chafla$Seq))
write.csv2(chfl.abun, "/Users/Artemis/Documents/GitHub/CORE/Camilo/Analisis/PPE/Others/Cha_Fla/ChaFla_PPE_CORE_ASV_Abundance.csv")
chfl.taxa <- dplyr::filter(ppe.taxa, ppe.taxa$Seq %in% all_of(chafla$Seq))
write.csv2(chfl.taxa, "/Users/Artemis/Documents/GitHub/CORE/Camilo/Analisis/PPE/Others/Cha_Fla/ChaFla_PPE_CORE_TAXA.csv")
```


```{r}
chfl.nms <- paste(chfl.taxa$ASV, chfl.taxa$Species, sep = "_")
chl.fas <- data.frame(names = chfl.nms, sequences = all_of(chfl.taxa$Seq))
seqRFLP::dataframe2fas(chl.fas, "/Users/Artemis/Documents/GitHub/CORE/Camilo/Analisis/PPE/Others/Cha_Fla/ChaFla_PPE_ASV_CORE.fasta")
```


```{r}
chfl.align <- "/Users/Artemis/Documents/GitHub/CORE/Camilo/Analisis/PPE/Others/Cha_Fla/Alignment/aligned_chafla.fasta"
dbConn <- dbConnect(SQLite(), ":memory:")
Seqs2DB(chfl.align, type = "FASTA", dbFile = dbConn, "")
x <- dbGetQuery(dbConn, "select description from Seqs")$description
Add2DB(myData = data.frame(identifier = x, stringsAsFactors = FALSE), dbConn)
consensus <- IdConsensus(dbConn, threshold = 0.3, minInformation = 0.1)
distance.matrix <- DistanceMatrix(consensus, correction = "Jukes-Cantor", processors = NULL, verbose = TRUE)
dendrogram <- IdClusters(distance.matrix, 
                         method = "ML", 
                         showPlot = TRUE,
                         type = "dendrogram", 
                         myXStringSet = consensus, 
                         processors = NULL, 
                         verbose = TRUE)
dbDisconnect(dbConn)
#Selected model TN93+G4
```


```{r}
clust <-as.dendrogram(as.hclust(dendrogram)) %>% set("branches_lwd", 0.3) %>% ladderize(right = TRUE)
plot(clust)
```


```{r}
chfl.asv <- chfl.abun
colnames(chfl.asv) <- chfl.nms
chfl.multialign <- readDNAMultipleAlignment("/Users/Artemis/Documents/GitHub/CORE/Camilo/Analisis/PPE/Others/Cha_Fla/Alignment/aligned_chafla.fasta", format = "fasta")
chfl.multistring <- as(chfl.multialign, "DNAStringSet")
BrowseSeqs(chfl.multistring, htmlFile = "/Users/Artemis/Documents/GitHub/CORE/Camilo/Imagenes/PPE/Others/Cha_Fla/ChaFla_PPE_multiple_alignment.html")
chfl.smatrix <- as.matrix(chfl.multialign) %>% rownames() %>% as.vector()
print(all(colnames(chfl.asv)%in%gtools::mixedsort(chfl.smatrix, decreasing = FALSE)))
sort.chfl <- chfl.asv[, rownames(as.matrix(chfl.multialign))]
chfl.heat <- heatmaply(heatmaply::normalize(vegan::decostand(sort.chfl, method = "hellinger")), 
                       Colv = clust, 
                       Rowv = NA, 
                       main = "Shared PPE ASV between Chañaral and Flamenco clustered by maximum likelihood", 
                       margins = c(50,50,70,0), 
                       grid_gap = 1, 
                       width = 1920, 
                       height = 1080, 
                       subplot_height = c(0.35, 0.65), 
                       color = viridis::viridis(n = 256, 
                                                alpha = 1, 
                                                begin = 0, 
                                                end = 1,
                                                option = "mako")
                       )
saveWidget(chfl.heat, file = "/Users/Artemis/Documents/GitHub/CORE/Camilo/Imagenes/PPE/Others/Cha_Fla/ChaFla_hellinger_normalized_heatmap.html")
```


```{r}
hupc <- aps.ppe %>% dplyr::filter(Chanaral == 0 & Flamenco == 0 & Huasco == 1 & Pta.Choros == 1 & Quintero == 0 & LasCruces == 0)
hupc.abun <- dplyr::select(ppe.asv, all_of(hupc$Seq))
write.csv2(hupc.abun, "/Users/Artemis/Documents/GitHub/CORE/Camilo/Analisis/PPE/Others/Hu_Pc/HuPc_PPE_CORE_ASV_Abundance.csv")
hupc.taxa <- dplyr::filter(ppe.taxa, ppe.taxa$Seq %in% all_of(hupc$Seq))
write.csv2(hupc.taxa, "/Users/Artemis/Documents/GitHub/CORE/Camilo/Analisis/PPE/Others/Hu_Pc/HuPc_PPE_CORE_TAXA.csv")
```


```{r}
hupc.nms <- paste(hupc.taxa$ASV, hupc.taxa$Species, sep = "_")
hupc.fas <- data.frame(names = hupc.nms, sequences = all_of(hupc.taxa$Seq))
seqRFLP::dataframe2fas(hupc.fas, "/Users/Artemis/Documents/GitHub/CORE/Camilo/Analisis/PPE/Others/Hu_Pc/HuPc_PPE_ASV_CORE.fasta")
```


```{r}
hupc.align <- "/Users/Artemis/Documents/GitHub/CORE/Camilo/Analisis/PPE/Others/Hu_Pc/Alignment/hupc_aligned.fasta"
dbConn <- dbConnect(SQLite(), ":memory:")
Seqs2DB(hupc.align, type = "FASTA", dbFile = dbConn, "")
x <- dbGetQuery(dbConn, "select description from Seqs")$description
Add2DB(myData = data.frame(identifier = x, stringsAsFactors = FALSE), dbConn)
consensus <- IdConsensus(dbConn, threshold = 0.3, minInformation = 0.1)
distance.matrix <- DistanceMatrix(consensus, correction = "Jukes-Cantor", processors = NULL, verbose = TRUE)
dendrogram <- IdClusters(distance.matrix, 
                         method = "ML", 
                         showPlot = TRUE,
                         type = "dendrogram", 
                         myXStringSet = consensus, 
                         processors = NULL, 
                         verbose = TRUE)
dbDisconnect(dbConn)
#Selected model... TN93 + G4
```


```{r}
clust <- as.dendrogram(as.hclust(dendrogram)) %>% set("branches_lwd", 0.3) %>% dendextend::ladderize(right = TRUE)
plot(clust)
```


```{r}
hupc.asv <- hupc.abun
colnames(hupc.asv) <- hupc.nms
hupc.multialign <- Biostrings::readDNAMultipleAlignment("/Users/Artemis/Documents/GitHub/CORE/Camilo/Analisis/PPE/Others/Hu_Pc/Alignment/hupc_aligned.fasta", format = "fasta")
hupc.multistring <- as(hupc.multialign, "DNAStringSet")
BrowseSeqs(hupc.multistring, htmlFile = "/Users/Artemis/Documents/GitHub/CORE/Camilo/Imagenes/PPE/Others/Hu_Pc/HuPc_PPE_multiple_alignment.html")
hupc.smatrix <- as.matrix(hupc.multialign) %>% rownames() %>% as.vector()
print(all(colnames(hupc.asv)%in%gtools::mixedsort(hupc.smatrix, decreasing = FALSE)))
sort.hupc <- hupc.asv[,rownames(as.matrix(hupc.multialign))]
hupc.heat <- heatmaply(heatmaply::normalize(vegan::decostand(sort.hupc, method = "hellinger")), 
                       Colv = clust, 
                       Rowv = NA, 
                       main = "Shared PPE ASV between Huasco and Punta de Choros clustered by maximum likelihood", 
                       margins = c(50,50,70,0), 
                       grid_gap = 1, 
                       width = 1920, 
                       height = 1080, 
                       subplot_height = c(0.35,0.65), 
                       color = viridis::viridis(n = 256, 
                                                alpha = 1, 
                                                begin = 0, 
                                                end = 1, 
                                                option = "mako")
                       )
saveWidget(hupc.heat, file = "/Users/Artemis/Documents/GitHub/CORE/Camilo/Imagenes/PPE/Others/Hu_Pc/HuPc_hellinger_normalized_heatmap.html")
```


```{r}
chahu <- aps.ppe %>% dplyr::filter(Chanaral == 1 & Flamenco == 0 & Huasco == 1 & Pta.Choros == 0 & Quintero == 0 & LasCruces == 0)
chahu.abun <- dplyr::select(ppe.asv, all_of(chahu$Seq))
write.csv2(chahu.abun, "/Users/Artemis/Documents/GitHub/CORE/Camilo/Analisis/PPE/Others/Cha_Hu/ChaHu_PPE_CORE_ASV_Abundance.csv")
chahu.taxa <- dplyr::filter(ppe.taxa, ppe.taxa$Seq %in% all_of(chahu$Seq))
write.csv2(chahu.taxa, "/Users/Artemis/Documents/GitHub/CORE/Camilo/Analisis/PPE/Others/Cha_Hu/ChaHu_PPE_CORE_TAXA.csv")
```


```{r}
chahu.nms <- paste(chahu.taxa$ASV, chahu.taxa$Species, sep = "_")
chahu.fas <- data.frame(names = chahu.nms, sequences = all_of(chahu.taxa$Seq))
seqRFLP::dataframe2fas(chahu.fas, "/Users/Artemis/Documents/GitHub/CORE/Camilo/Analisis/PPE/Others/Cha_Hu/ChaHu_PPE_ASV_CORE.fasta")
```


```{r}
chahu.align <- "/Users/Artemis/Documents/GitHub/CORE/Camilo/Analisis/PPE/Others/Cha_Hu/Alignment/chahu_aligned.fasta"
dbConn <- dbConnect(SQLite(), ":memory:")
Seqs2DB(chahu.align, type = "FASTA", dbFile = dbConn, "")
x <- dbGetQuery(dbConn, "select description from Seqs")$description
Add2DB(myData = data.frame(identifier = x, stringsAsFactors = FALSE), dbConn)
consensus <- IdConsensus(dbConn, threshold = 0.3, minInformation = 0.1)
distance.matrix <- DistanceMatrix(consensus, 
                                  correction = "Jukes-Cantor", 
                                  processors = NULL, 
                                  verbose = TRUE)
dendrogram <- IdClusters(distance.matrix, 
                         method = "ML", 
                         showPlot = TRUE, 
                         type = "dendrogram", 
                         myXStringSet = consensus, 
                         processors = NULL, 
                         verbose = TRUE)
dbDisconnect(dbConn)
#Selected model... TN93+G4
```


```{r}
clust <- as.dendrogram(as.hclust(dendrogram)) %>% set("branches_lwd", 0.3) %>% dendextend::ladderize(right = TRUE)
plot(clust)
```


```{r}
chahu.asv <- chahu.abun
colnames(chahu.asv) <- chahu.nms
chahu.multialign <- Biostrings::readAAMultipleAlignment("/Users/Artemis/Documents/GitHub/CORE/Camilo/Analisis/PPE/Others/Cha_Hu/Alignment/chahu_aligned.fasta", format = "fasta")
chahu.multistring <- as(chahu.multialign, "DNAStringSet")
BrowseSeqs(chahu.multistring, htmlFile = "/Users/Artemis/Documents/GitHub/CORE/Camilo/Imagenes/PPE/Others/Cha_Hu/ChaHu_PPE_multiple_alignment.html")
chahu.smatrix <- as.matrix(chahu.multialign) %>% rownames() %>% as.vector()
print(all(colnames(chahu.asv)%in%gtools::mixedsort(chahu.smatrix, decreasing = FALSE)))
sort.chahu <- chahu.asv[,rownames(as.matrix(chahu.multialign))]
chahu.heat <- heatmaply::heatmaply(normalize(vegan::decostand(sort.chahu, method = "hellinger")), 
                                   Colv = clust, 
                                   Rowv = NA, 
                                   main = "Shared PPE ASV between Chañaral and Huasco clustered by maximun likelihood", 
                                   margins = c(50,50,70,0), 
                                   grid_gap = 1, 
                                   width = 1920, 
                                   height = 1080, 
                                   subplot_height = c(0.45,0.55), 
                                   color = viridis::viridis(n = 256, 
                                                            alpha = 1, 
                                                            begin = 0, 
                                                            end = 1, 
                                                            option = "mako")
                                   )
saveWidget(chahu.heat, file = "/Users/Artemis/Documents/GitHub/CORE/Camilo/Imagenes/PPE/Others/Cha_Hu/ChaHu_hellinger_normalized_heatmap.html")
```







